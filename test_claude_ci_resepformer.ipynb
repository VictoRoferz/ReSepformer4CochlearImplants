{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMU9T8ihdB+E8BoRyf0HyjI"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b648094105334cd5a5df4a2ebc7be67a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_194428c8ef8e4271896d6aab41c5d006",
              "IPY_MODEL_3bdec59b7cbe47c48d9df87d42a419c2",
              "IPY_MODEL_d164f3399699448a813e2583acc890a6"
            ],
            "layout": "IPY_MODEL_dbbce47da68745799b158d80fb46a565"
          }
        },
        "194428c8ef8e4271896d6aab41c5d006": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f90c10e57b1f4f50afca1594e708b630",
            "placeholder": "​",
            "style": "IPY_MODEL_73dcfd5c8b184c769ba55f537a787951",
            "value": "hyperparams.yaml: "
          }
        },
        "3bdec59b7cbe47c48d9df87d42a419c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6a5cfc91261c43a7b2c33ac8304c0e51",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_97080d836c234ff48bf428af1e952bc6",
            "value": 1
          }
        },
        "d164f3399699448a813e2583acc890a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b2fc6d40ac4e4044a3a8b51e3b059c37",
            "placeholder": "​",
            "style": "IPY_MODEL_971bb890c38f447199cf857d4b4f6201",
            "value": " 1.51k/? [00:00&lt;00:00, 113kB/s]"
          }
        },
        "dbbce47da68745799b158d80fb46a565": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f90c10e57b1f4f50afca1594e708b630": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "73dcfd5c8b184c769ba55f537a787951": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6a5cfc91261c43a7b2c33ac8304c0e51": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "97080d836c234ff48bf428af1e952bc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b2fc6d40ac4e4044a3a8b51e3b059c37": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "971bb890c38f447199cf857d4b4f6201": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6df56b1eaa91497ab3924dee1037f2f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_14736c8b05d640ac94e330416ee47eac",
              "IPY_MODEL_f16b7af036ce4ba78cb0d981d12e9c0b",
              "IPY_MODEL_35e5d595b7c2491ea355fb77fce02749"
            ],
            "layout": "IPY_MODEL_fe400a5d002c443f910719164b3dceef"
          }
        },
        "14736c8b05d640ac94e330416ee47eac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8d761d890f4b47cbb3aac41c962c16e6",
            "placeholder": "​",
            "style": "IPY_MODEL_92a45741044e4dd8828b4a1a61d0d431",
            "value": "encoder.ckpt: 100%"
          }
        },
        "f16b7af036ce4ba78cb0d981d12e9c0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_109a1b0d78bf4861aac0c19fac1af0d9",
            "max": 9067,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f391e8c4c9df476e863868b26ba1df0f",
            "value": 9067
          }
        },
        "35e5d595b7c2491ea355fb77fce02749": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a8eb20cc643f4bb3a8e7996c39a7912a",
            "placeholder": "​",
            "style": "IPY_MODEL_2e768a517ba042149570df7b346060c9",
            "value": " 9.07k/9.07k [00:00&lt;00:00, 982kB/s]"
          }
        },
        "fe400a5d002c443f910719164b3dceef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d761d890f4b47cbb3aac41c962c16e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "92a45741044e4dd8828b4a1a61d0d431": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "109a1b0d78bf4861aac0c19fac1af0d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f391e8c4c9df476e863868b26ba1df0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a8eb20cc643f4bb3a8e7996c39a7912a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e768a517ba042149570df7b346060c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8ac9587ded164613a1fff112996dbf70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e83910c8623c4530a9a8388e18aac414",
              "IPY_MODEL_a64dbadbd26c40f687439806019ae31d",
              "IPY_MODEL_f179345b10a84a17ad0fb7cc7e76a8d8"
            ],
            "layout": "IPY_MODEL_f56e59b34a5f4dd6951fa8afc4c49f48"
          }
        },
        "e83910c8623c4530a9a8388e18aac414": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_99dc67e1f7374ac6bb19597956411934",
            "placeholder": "​",
            "style": "IPY_MODEL_5c5507b155e7414c91711dce0ee4bbec",
            "value": "masknet.ckpt: 100%"
          }
        },
        "a64dbadbd26c40f687439806019ae31d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2144ab6317f14992a19564ca8c41a4df",
            "max": 185533341,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ac74131bfc1b48c797ce5a7417c0b374",
            "value": 185533341
          }
        },
        "f179345b10a84a17ad0fb7cc7e76a8d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_30822ea43dcf45e789847f6490e9f2c4",
            "placeholder": "​",
            "style": "IPY_MODEL_79420baf401943bba56d318cf52789fa",
            "value": " 186M/186M [00:01&lt;00:00, 118MB/s]"
          }
        },
        "f56e59b34a5f4dd6951fa8afc4c49f48": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "99dc67e1f7374ac6bb19597956411934": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c5507b155e7414c91711dce0ee4bbec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2144ab6317f14992a19564ca8c41a4df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac74131bfc1b48c797ce5a7417c0b374": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "30822ea43dcf45e789847f6490e9f2c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "79420baf401943bba56d318cf52789fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "48b269935d8d462896b29ad71780b47a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9c4f1b65ce49448887863aeec5b8783a",
              "IPY_MODEL_5a61236865de452bab64e6d73ef1b9d6",
              "IPY_MODEL_cd90c47ade0d4b74b5de94764537cfac"
            ],
            "layout": "IPY_MODEL_683c54d13e0a43b1b7a82ac804b2e78e"
          }
        },
        "9c4f1b65ce49448887863aeec5b8783a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_97cfe2a97fb14657b8fd7d8ad923dda5",
            "placeholder": "​",
            "style": "IPY_MODEL_a92750c44cba4f8ba9ba62136c8821da",
            "value": "decoder.ckpt: 100%"
          }
        },
        "5a61236865de452bab64e6d73ef1b9d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_af0815ae1fce461cb33727aca6108c69",
            "max": 9003,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6c4393a6667f410484838c5c3d4eb2af",
            "value": 9003
          }
        },
        "cd90c47ade0d4b74b5de94764537cfac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a6d39b9aa04a427390a5a4e5c9e7e968",
            "placeholder": "​",
            "style": "IPY_MODEL_d3fe9cbbca704e2eabc0aadc56b790b2",
            "value": " 9.00k/9.00k [00:00&lt;00:00, 690kB/s]"
          }
        },
        "683c54d13e0a43b1b7a82ac804b2e78e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "97cfe2a97fb14657b8fd7d8ad923dda5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a92750c44cba4f8ba9ba62136c8821da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "af0815ae1fce461cb33727aca6108c69": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c4393a6667f410484838c5c3d4eb2af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a6d39b9aa04a427390a5a4e5c9e7e968": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d3fe9cbbca704e2eabc0aadc56b790b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\"\"\"\n",
        "Google Colab Setup for RE-SepFormer CI Project\n",
        "Run this notebook in Google Colab to set up the environment and download data\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "JCLZK5hp-gRL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "RE-SepFormer CI Project Workflow ===\n",
        "\n",
        "1. DATA PREPARATION:\n",
        "   - LibriSpeech train-clean-100 (100 hours)\n",
        "   - WHAM! noise dataset (or synthetic noise)\n",
        "   - Create multi-talker babble (1, 2, 4 speakers)\n",
        "   - Mix at SNRs 1-10 dB\n",
        "\n",
        "2. MODEL ARCHITECTURE (RE-SepFormer):\n",
        "   - Uses SpeechBrain's ResourceEfficientSeparator\n",
        "   - Key features: Non-overlapping chunks, memory averaging\n",
        "   - 8M parameters (vs 26M for SepFormer)\n",
        "   \n",
        "3. TRAINING:\n",
        "   - Loss: SI-SNR (Scale-Invariant SNR)\n",
        "   - Optimizer: Adam with learning rate scheduling\n",
        "   - 100 epochs (reduced to 5 for demo)\n",
        "   \n",
        "4. EVALUATION:\n",
        "   - Metrics: SI-SDR improvement, PESQ, STOI\n",
        "   - Test on different noise types and SNRs\n",
        "   - Compare with Paper 1 results\n",
        "   \n",
        "5. CI TESTING:\n",
        "   - Export processed audio files\n",
        "   - 20 sentences per condition\n",
        "   - Ready for behavioral testing\n",
        "\n",
        "To run the complete pipeline:\n",
        "1. Execute all cells in order\n",
        "2. Monitor training progress\n",
        "3. Review evaluation metrics\n",
        "4. Export audio for CI testing"
      ],
      "metadata": {
        "id": "szHNoXRea7ml"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "WdDfte2R9T1u"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "# Installing SpeechBrain via pip\n",
        "BRANCH = 'develop'\n",
        "!python -m pip install git+https://github.com/speechbrain/speechbrain.git@$BRANCH\n",
        "\n",
        "# Clone SpeechBrain repository\n",
        "!git clone https://github.com/speechbrain/speechbrain/\n",
        "%cd /content/speechbrain/templates/speech_recognition/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m pip install git+https://github.com/speechbrain/speechbrain.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mYL_eXdw-Kmn",
        "outputId": "04f5f6b4-fec0-429b-e386-564cf45b1701"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/speechbrain/speechbrain.git\n",
            "  Cloning https://github.com/speechbrain/speechbrain.git to /tmp/pip-req-build-ijbiqpuv\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/speechbrain/speechbrain.git /tmp/pip-req-build-ijbiqpuv\n",
            "  Resolved https://github.com/speechbrain/speechbrain.git to commit c75ab5489431fd0a2a7d21160bc37677801cb506\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: hyperpyyaml in /usr/local/lib/python3.11/dist-packages (from speechbrain==1.0.3) (1.2.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from speechbrain==1.0.3) (1.5.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from speechbrain==1.0.3) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from speechbrain==1.0.3) (24.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from speechbrain==1.0.3) (1.15.3)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from speechbrain==1.0.3) (0.2.0)\n",
            "Requirement already satisfied: torch>=1.9 in /usr/local/lib/python3.11/dist-packages (from speechbrain==1.0.3) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (from speechbrain==1.0.3) (2.6.0+cu124)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from speechbrain==1.0.3) (4.67.1)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (from speechbrain==1.0.3) (0.33.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain==1.0.3) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain==1.0.3) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain==1.0.3) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain==1.0.3) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain==1.0.3) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain==1.0.3) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain==1.0.3) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain==1.0.3) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain==1.0.3) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain==1.0.3) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain==1.0.3) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain==1.0.3) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain==1.0.3) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain==1.0.3) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain==1.0.3) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain==1.0.3) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain==1.0.3) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain==1.0.3) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain==1.0.3) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain==1.0.3) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.9->speechbrain==1.0.3) (1.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->speechbrain==1.0.3) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->speechbrain==1.0.3) (2.32.3)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->speechbrain==1.0.3) (1.1.5)\n",
            "Requirement already satisfied: ruamel.yaml>=0.17.28 in /usr/local/lib/python3.11/dist-packages (from hyperpyyaml->speechbrain==1.0.3) (0.18.14)\n",
            "Requirement already satisfied: ruamel.yaml.clib>=0.2.7 in /usr/local/lib/python3.11/dist-packages (from ruamel.yaml>=0.17.28->hyperpyyaml->speechbrain==1.0.3) (0.2.12)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.9->speechbrain==1.0.3) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->speechbrain==1.0.3) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->speechbrain==1.0.3) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->speechbrain==1.0.3) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->speechbrain==1.0.3) (2025.6.15)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "!pip install speechbrain\n",
        "!pip install pesq\n",
        "!pip install pystoi\n",
        "!pip install mir_eval\n",
        "!pip install hyperpyyaml\n",
        "!pip install soundfile librosa\n",
        "!pip install pandas numpy scipy matplotlib seaborn tqdm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7aOx_9ktBEOH",
        "outputId": "b3b9101c-1d1b-4f4f-bb3f-133c2b0591d3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.2.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: speechbrain in /usr/local/lib/python3.11/dist-packages (1.0.3)\n",
            "Requirement already satisfied: hyperpyyaml in /usr/local/lib/python3.11/dist-packages (from speechbrain) (1.2.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from speechbrain) (1.5.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from speechbrain) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from speechbrain) (24.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from speechbrain) (1.15.3)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from speechbrain) (0.2.0)\n",
            "Requirement already satisfied: torch>=1.9 in /usr/local/lib/python3.11/dist-packages (from speechbrain) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (from speechbrain) (2.6.0+cu124)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from speechbrain) (4.67.1)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (from speechbrain) (0.33.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.9->speechbrain) (1.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->speechbrain) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->speechbrain) (2.32.3)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->speechbrain) (1.1.5)\n",
            "Requirement already satisfied: ruamel.yaml>=0.17.28 in /usr/local/lib/python3.11/dist-packages (from hyperpyyaml->speechbrain) (0.18.14)\n",
            "Requirement already satisfied: ruamel.yaml.clib>=0.2.7 in /usr/local/lib/python3.11/dist-packages (from ruamel.yaml>=0.17.28->hyperpyyaml->speechbrain) (0.2.12)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.9->speechbrain) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->speechbrain) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->speechbrain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->speechbrain) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->speechbrain) (2025.6.15)\n",
            "Collecting pesq\n",
            "  Downloading pesq-0.0.4.tar.gz (38 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: pesq\n",
            "  Building wheel for pesq (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pesq: filename=pesq-0.0.4-cp311-cp311-linux_x86_64.whl size=274952 sha256=5ba6189616eb10c5dcd89ed72136e49d147997cafd60227dd16b2799b5ca8fd0\n",
            "  Stored in directory: /root/.cache/pip/wheels/ae/f1/23/2698d0bf31eec2b2aa50623b5d93b6206c49c7155d0e31345d\n",
            "Successfully built pesq\n",
            "Installing collected packages: pesq\n",
            "Successfully installed pesq-0.0.4\n",
            "Collecting pystoi\n",
            "  Downloading pystoi-0.4.1-py2.py3-none-any.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from pystoi) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from pystoi) (1.15.3)\n",
            "Downloading pystoi-0.4.1-py2.py3-none-any.whl (8.2 kB)\n",
            "Installing collected packages: pystoi\n",
            "Successfully installed pystoi-0.4.1\n",
            "Collecting mir_eval\n",
            "  Downloading mir_eval-0.8.2-py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.11/dist-packages (from mir_eval) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from mir_eval) (1.15.3)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from mir_eval) (4.4.2)\n",
            "Downloading mir_eval-0.8.2-py3-none-any.whl (102 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.8/102.8 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: mir_eval\n",
            "Successfully installed mir_eval-0.8.2\n",
            "Requirement already satisfied: hyperpyyaml in /usr/local/lib/python3.11/dist-packages (1.2.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from hyperpyyaml) (6.0.2)\n",
            "Requirement already satisfied: ruamel.yaml>=0.17.28 in /usr/local/lib/python3.11/dist-packages (from hyperpyyaml) (0.18.14)\n",
            "Requirement already satisfied: ruamel.yaml.clib>=0.2.7 in /usr/local/lib/python3.11/dist-packages (from ruamel.yaml>=0.17.28->hyperpyyaml) (0.2.12)\n",
            "Requirement already satisfied: soundfile in /usr/local/lib/python3.11/dist-packages (0.13.1)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.11/dist-packages (0.11.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile) (1.17.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from soundfile) (2.0.2)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa) (3.0.1)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.60.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.15.3)\n",
            "Requirement already satisfied: scikit-learn>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.6.1)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.5.1)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.5.0.post1)\n",
            "Requirement already satisfied: typing_extensions>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.14.0)\n",
            "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.1.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile) (2.22)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from lazy_loader>=0.1->librosa) (24.2)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.0->librosa) (0.43.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (4.3.8)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (2.32.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.1.0->librosa) (3.6.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2025.6.15)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (1.15.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.4)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os"
      ],
      "metadata": {
        "id": "5wcrAgyTBJbo"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ip11Hi1BK-J",
        "outputId": "f5839832-2e42-4d1a-9585-b0ff88a40111"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch version: 2.6.0+cu124\n",
            "CUDA available: False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.request\n",
        "import tarfile\n",
        "from tqdm import tqdm\n",
        "import shutil"
      ],
      "metadata": {
        "id": "M3eAOZviBtCw"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vrK84FeS9Bgh",
        "outputId": "40149ede-3441-4d7d-d7ee-a087c3e6cccc"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your runtime has 54.8 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir(\"/content/speechbrain/\")"
      ],
      "metadata": {
        "id": "QxEHFaPBTDmB"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.getcwd()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "MCAaMNDETK3j",
        "outputId": "106fdaa8-7c0d-4cbc-d4c9-240def37d69b"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/speechbrain'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#%cd speechbrain/\n",
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pXIbqdElSsWS",
        "outputId": "b4f4e1c2-6975-4ca2-9d4f-f9e4530bc964"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ignoring SoundFile: markers 'sys_platform == \"win32\"' don't match your environment\n",
            "Collecting black==24.3.0 (from -r lint-requirements.txt (line 1))\n",
            "  Downloading black-24.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.0/76.0 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting click==8.1.7 (from -r lint-requirements.txt (line 2))\n",
            "  Downloading click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting flake8==7.0.0 (from -r lint-requirements.txt (line 3))\n",
            "  Downloading flake8-7.0.0-py2.py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting isort==5.13.2 (from -r lint-requirements.txt (line 4))\n",
            "  Downloading isort-5.13.2-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting pycodestyle==2.11.0 (from -r lint-requirements.txt (line 5))\n",
            "  Downloading pycodestyle-2.11.0-py2.py3-none-any.whl.metadata (4.5 kB)\n",
            "Collecting pydoclint==0.4.1 (from -r lint-requirements.txt (line 6))\n",
            "  Downloading pydoclint-0.4.1-py2.py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting pytest==7.4.0 (from -r lint-requirements.txt (line 7))\n",
            "  Downloading pytest-7.4.0-py3-none-any.whl.metadata (8.0 kB)\n",
            "Collecting yamllint==1.35.1 (from -r lint-requirements.txt (line 8))\n",
            "  Downloading yamllint-1.35.1-py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: huggingface_hub>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 2)) (0.33.0)\n",
            "Requirement already satisfied: hyperpyyaml>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 3)) (1.2.2)\n",
            "Requirement already satisfied: joblib>=0.14.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 4)) (1.5.1)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 5)) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 6)) (24.2)\n",
            "Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 7)) (2.2.2)\n",
            "Collecting pre-commit>=2.3.0 (from -r requirements.txt (line 8))\n",
            "  Downloading pre_commit-4.2.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 9)) (1.15.3)\n",
            "Requirement already satisfied: sentencepiece>=0.1.91 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 10)) (0.2.0)\n",
            "Requirement already satisfied: torch>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 12)) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchaudio>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 13)) (2.6.0+cu124)\n",
            "Requirement already satisfied: tqdm>=4.42.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 14)) (4.67.1)\n",
            "Requirement already satisfied: transformers>=4.30.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 15)) (4.52.4)\n",
            "Collecting mypy-extensions>=0.4.3 (from black==24.3.0->-r lint-requirements.txt (line 1))\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting pathspec>=0.9.0 (from black==24.3.0->-r lint-requirements.txt (line 1))\n",
            "  Downloading pathspec-0.12.1-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: platformdirs>=2 in /usr/local/lib/python3.11/dist-packages (from black==24.3.0->-r lint-requirements.txt (line 1)) (4.3.8)\n",
            "Collecting mccabe<0.8.0,>=0.7.0 (from flake8==7.0.0->-r lint-requirements.txt (line 3))\n",
            "  Downloading mccabe-0.7.0-py2.py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting pyflakes<3.3.0,>=3.2.0 (from flake8==7.0.0->-r lint-requirements.txt (line 3))\n",
            "  Downloading pyflakes-3.2.0-py2.py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting docstring-parser-fork>=0.0.5 (from pydoclint==0.4.1->-r lint-requirements.txt (line 6))\n",
            "  Downloading docstring_parser_fork-0.0.12-py3-none-any.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.11/dist-packages (from pytest==7.4.0->-r lint-requirements.txt (line 7)) (2.1.0)\n",
            "Requirement already satisfied: pluggy<2.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from pytest==7.4.0->-r lint-requirements.txt (line 7)) (1.6.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from yamllint==1.35.1->-r lint-requirements.txt (line 8)) (6.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.8.0->-r requirements.txt (line 2)) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.8.0->-r requirements.txt (line 2)) (2025.3.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.8.0->-r requirements.txt (line 2)) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.8.0->-r requirements.txt (line 2)) (4.14.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.8.0->-r requirements.txt (line 2)) (1.1.5)\n",
            "Requirement already satisfied: ruamel.yaml>=0.17.28 in /usr/local/lib/python3.11/dist-packages (from hyperpyyaml>=0.0.1->-r requirements.txt (line 3)) (0.18.14)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.1->-r requirements.txt (line 7)) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.1->-r requirements.txt (line 7)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.1->-r requirements.txt (line 7)) (2025.2)\n",
            "Collecting cfgv>=2.0.0 (from pre-commit>=2.3.0->-r requirements.txt (line 8))\n",
            "  Downloading cfgv-3.4.0-py2.py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting identify>=1.0.0 (from pre-commit>=2.3.0->-r requirements.txt (line 8))\n",
            "  Downloading identify-2.6.12-py2.py3-none-any.whl.metadata (4.4 kB)\n",
            "Collecting nodeenv>=0.11.1 (from pre-commit>=2.3.0->-r requirements.txt (line 8))\n",
            "  Downloading nodeenv-1.9.1-py2.py3-none-any.whl.metadata (21 kB)\n",
            "Collecting virtualenv>=20.10.0 (from pre-commit>=2.3.0->-r requirements.txt (line 8))\n",
            "  Downloading virtualenv-20.31.2-py3-none-any.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->-r requirements.txt (line 12)) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->-r requirements.txt (line 12)) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->-r requirements.txt (line 12)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->-r requirements.txt (line 12)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->-r requirements.txt (line 12)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->-r requirements.txt (line 12)) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->-r requirements.txt (line 12)) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->-r requirements.txt (line 12)) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->-r requirements.txt (line 12)) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->-r requirements.txt (line 12)) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->-r requirements.txt (line 12)) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->-r requirements.txt (line 12)) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->-r requirements.txt (line 12)) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->-r requirements.txt (line 12)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->-r requirements.txt (line 12)) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->-r requirements.txt (line 12)) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->-r requirements.txt (line 12)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.1.0->-r requirements.txt (line 12)) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.30.0->-r requirements.txt (line 15)) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.30.0->-r requirements.txt (line 15)) (0.21.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.30.0->-r requirements.txt (line 15)) (0.5.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.1->-r requirements.txt (line 7)) (1.17.0)\n",
            "Requirement already satisfied: ruamel.yaml.clib>=0.2.7 in /usr/local/lib/python3.11/dist-packages (from ruamel.yaml>=0.17.28->hyperpyyaml>=0.0.1->-r requirements.txt (line 3)) (0.2.12)\n",
            "Collecting distlib<1,>=0.3.7 (from virtualenv>=20.10.0->pre-commit>=2.3.0->-r requirements.txt (line 8))\n",
            "  Downloading distlib-0.3.9-py2.py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.1.0->-r requirements.txt (line 12)) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.8.0->-r requirements.txt (line 2)) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.8.0->-r requirements.txt (line 2)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.8.0->-r requirements.txt (line 2)) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.8.0->-r requirements.txt (line 2)) (2025.6.15)\n",
            "Downloading black-24.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading click-8.1.7-py3-none-any.whl (97 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.9/97.9 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading flake8-7.0.0-py2.py3-none-any.whl (57 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading isort-5.13.2-py3-none-any.whl (92 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.3/92.3 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pycodestyle-2.11.0-py2.py3-none-any.whl (31 kB)\n",
            "Downloading pydoclint-0.4.1-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/41.0 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytest-7.4.0-py3-none-any.whl (323 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m323.6/323.6 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading yamllint-1.35.1-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.7/66.7 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pre_commit-4.2.0-py2.py3-none-any.whl (220 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m220.7/220.7 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cfgv-3.4.0-py2.py3-none-any.whl (7.2 kB)\n",
            "Downloading docstring_parser_fork-0.0.12-py3-none-any.whl (42 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading identify-2.6.12-py2.py3-none-any.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mccabe-0.7.0-py2.py3-none-any.whl (7.3 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Downloading nodeenv-1.9.1-py2.py3-none-any.whl (22 kB)\n",
            "Downloading pathspec-0.12.1-py3-none-any.whl (31 kB)\n",
            "Downloading pyflakes-3.2.0-py2.py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading virtualenv-20.31.2-py3-none-any.whl (6.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.1/6.1 MB\u001b[0m \u001b[31m35.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading distlib-0.3.9-py2.py3-none-any.whl (468 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m469.0/469.0 kB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: distlib, virtualenv, pytest, pyflakes, pycodestyle, pathspec, nodeenv, mypy-extensions, mccabe, isort, identify, docstring-parser-fork, click, cfgv, yamllint, pydoclint, pre-commit, flake8, black\n",
            "  Attempting uninstall: pytest\n",
            "    Found existing installation: pytest 8.3.5\n",
            "    Uninstalling pytest-8.3.5:\n",
            "      Successfully uninstalled pytest-8.3.5\n",
            "  Attempting uninstall: click\n",
            "    Found existing installation: click 8.2.1\n",
            "    Uninstalling click-8.2.1:\n",
            "      Successfully uninstalled click-8.2.1\n",
            "Successfully installed black-24.3.0 cfgv-3.4.0 click-8.1.7 distlib-0.3.9 docstring-parser-fork-0.0.12 flake8-7.0.0 identify-2.6.12 isort-5.13.2 mccabe-0.7.0 mypy-extensions-1.1.0 nodeenv-1.9.1 pathspec-0.12.1 pre-commit-4.2.0 pycodestyle-2.11.0 pydoclint-0.4.1 pyflakes-3.2.0 pytest-7.4.0 virtualenv-20.31.2 yamllint-1.35.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def download_with_progress(url, filename):\n",
        "    \"\"\"Download file with progress bar\"\"\"\n",
        "    class DownloadProgressBar(tqdm):\n",
        "        def update_to(self, b=1, bsize=1, tsize=None):\n",
        "            if tsize is not None:\n",
        "                self.total = tsize\n",
        "            self.update(b * bsize - self.n)\n",
        "\n",
        "    with DownloadProgressBar(unit='B', unit_scale=True, miniters=1, desc=filename) as t:\n",
        "        urllib.request.urlretrieve(url, filename, reporthook=t.update_to)"
      ],
      "metadata": {
        "id": "HrKfWHdIBvJf"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!df -h /content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jGt5ifeIB392",
        "outputId": "06569e6a-50f4-41b3-fa1c-fcc68cd6ac6e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filesystem      Size  Used Avail Use% Mounted on\n",
            "overlay         226G   42G  184G  19% /\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.getcwd()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "XuePi68QC-Xf",
        "outputId": "46b575d5-05d6-4419-8434-3cd61d75622e"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/speechbrain'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir('/content')"
      ],
      "metadata": {
        "id": "v8-ykjT6DXxM"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.getcwd()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "sX2yvuYWDg--",
        "outputId": "78963124-f01a-4f3c-bfe3-ce7ec96be8e4"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs('data/raw', exist_ok=True)\n"
      ],
      "metadata": {
        "id": "SN990I12CoBh"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create directory structure\n",
        "directories = [\n",
        "    'data/raw/librispeech',\n",
        "    'data/raw/wham',\n",
        "    'data/raw/ieee',\n",
        "    'data/processed/train',\n",
        "    'data/processed/val',\n",
        "    'data/processed/test',\n",
        "    'models/checkpoints',\n",
        "    'scripts',\n",
        "    'configs',\n",
        "    'utils',\n",
        "    'results/plots',\n",
        "    'notebooks'\n",
        "]\n",
        "\n",
        "\n",
        "for dir_path in directories:\n",
        "    os.makedirs(dir_path, exist_ok=True)"
      ],
      "metadata": {
        "id": "LNtBE8sjC00b"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.exists('data/raw/librispeech/train-clean-100'):\n",
        "    print(\"Downloading LibriSpeech train-clean-100...\")\n",
        "    download_with_progress(\n",
        "        'https://www.openslr.org/resources/12/train-clean-100.tar.gz',\n",
        "        'train-clean-100.tar.gz'\n",
        "    )\n",
        "\n",
        "    print(\"Extracting...\")\n",
        "    with tarfile.open('train-clean-100.tar.gz', 'r:gz') as tar:\n",
        "        tar.extractall('data/raw/librispeech/')\n",
        "\n",
        "    # Clean up\n",
        "    os.remove('train-clean-100.tar.gz')\n",
        "    print(\"LibriSpeech downloaded and extracted!\")\n",
        "else:\n",
        "    print(\"LibriSpeech already exists!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gESMIdT6B8nE",
        "outputId": "515820b8-19c1-41bc-d963-dcf263ae4d79"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading LibriSpeech train-clean-100...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train-clean-100.tar.gz: 6.39GB [04:27, 23.9MB/s]                            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting...\n",
            "LibriSpeech downloaded and extracted!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -L -o wham_noise.zip https://my-bucket-a8b4b49c25c811ee9a7e8bba05fa24c7.s3.amazonaws.com/wham_noise.zip\n",
        "!unzip -q wham_noise.zip -d data/raw/wham/\n",
        "!rm wham_noise.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cnbahusADpe-",
        "outputId": "421455e3-728e-4d5e-8252-52434cb77038"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 16.9G  100 16.9G    0     0  45.3M      0  0:06:22  0:06:22 --:--:-- 45.2M\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import soundfile as sf\n",
        "import torch\n",
        "import torchaudio\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "jiJ4jdM7FYKT"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CIDataPreparer:\n",
        "    def __init__(self, librispeech_path, wham_path, output_path, sample_rate=16000):\n",
        "        \"\"\"Initialize data preparer\"\"\"\n",
        "        self.librispeech_path = Path(librispeech_path)\n",
        "        self.wham_path = Path(wham_path)\n",
        "        self.output_path = Path(output_path)\n",
        "        self.sample_rate = sample_rate\n",
        "\n",
        "        # Create output directories\n",
        "        self.output_path.mkdir(parents=True, exist_ok=True)\n",
        "        (self.output_path / 'train').mkdir(exist_ok=True)\n",
        "        (self.output_path / 'val').mkdir(exist_ok=True)\n",
        "        (self.output_path / 'test').mkdir(exist_ok=True)\n",
        "\n",
        "    def load_audio(self, path, target_sr=16000):\n",
        "        \"\"\"Load audio file and resample if necessary\"\"\"\n",
        "        try:\n",
        "            audio, sr = torchaudio.load(path)\n",
        "        except:\n",
        "            # Fallback to soundfile\n",
        "            audio, sr = sf.read(path)\n",
        "            audio = torch.FloatTensor(audio).unsqueeze(0)\n",
        "\n",
        "        # Convert to mono if stereo\n",
        "        if audio.shape[0] > 1:\n",
        "            audio = torch.mean(audio, dim=0, keepdim=True)\n",
        "\n",
        "        # Resample if necessary\n",
        "        if sr != target_sr:\n",
        "            resampler = torchaudio.transforms.Resample(sr, target_sr)\n",
        "            audio = resampler(audio)\n",
        "\n",
        "        return audio.numpy()[0], target_sr\n",
        "\n",
        "    def create_multi_talker_babble(self, speech_files, num_talkers):\n",
        "        \"\"\"Create multi-talker babble from speech files\"\"\"\n",
        "        # Randomly select speakers\n",
        "        selected_files = random.sample(speech_files, min(num_talkers, len(speech_files)))\n",
        "\n",
        "        # Load first speaker\n",
        "        babble, sr = self.load_audio(selected_files[0])\n",
        "\n",
        "        # Mix additional speakers\n",
        "        for file in selected_files[1:]:\n",
        "            audio, _ = self.load_audio(file)\n",
        "\n",
        "            # Match lengths\n",
        "            min_len = min(len(babble), len(audio))\n",
        "            babble = babble[:min_len] + audio[:min_len]\n",
        "\n",
        "        # Normalize\n",
        "        babble = babble / (np.max(np.abs(babble)) + 1e-8)\n",
        "\n",
        "        return babble\n",
        "\n",
        "    def mix_audio_at_snr(self, speech, noise, snr_db):\n",
        "        \"\"\"Mix speech and noise at specified SNR\"\"\"\n",
        "        # Match lengths\n",
        "        min_len = min(len(speech), len(noise))\n",
        "        speech = speech[:min_len]\n",
        "        noise = noise[:min_len]\n",
        "\n",
        "        # Calculate power\n",
        "        speech_power = np.mean(speech ** 2) + 1e-8\n",
        "        noise_power = np.mean(noise ** 2) + 1e-8\n",
        "\n",
        "        # Calculate scaling factor\n",
        "        snr_linear = 10 ** (snr_db / 10)\n",
        "        noise_scale = np.sqrt(speech_power / (noise_power * snr_linear))\n",
        "\n",
        "        # Scale noise and mix\n",
        "        noise_scaled = noise * noise_scale\n",
        "        mixture = speech + noise_scaled\n",
        "\n",
        "        # Prevent clipping\n",
        "        max_val = np.max(np.abs(mixture))\n",
        "        if max_val > 0.95:\n",
        "            scale = 0.95 / max_val\n",
        "            mixture *= scale\n",
        "            speech *= scale\n",
        "            noise_scaled *= scale\n",
        "\n",
        "        return mixture, speech, noise_scaled\n",
        "\n",
        "    def prepare_training_data(self, num_mixtures=100):  # Reduced for Colab\n",
        "        \"\"\"Prepare training data (reduced for Colab demo)\"\"\"\n",
        "        print(\"Preparing training data...\")\n",
        "\n",
        "        # Get LibriSpeech file list\n",
        "        speech_files = list(self.librispeech_path.glob('**/*.flac'))\n",
        "        print(f\"Found {len(speech_files)} speech files\")\n",
        "\n",
        "        # Get WHAM! noise files\n",
        "        noise_files = list(self.wham_path.glob('**/*.wav'))\n",
        "        print(f\"Found {len(noise_files)} noise files\")\n",
        "\n",
        "        if len(speech_files) == 0:\n",
        "            raise ValueError(\"No speech files found!\")\n",
        "\n",
        "        # SNR range as per Paper 1\n",
        "        snr_range = range(1, 11)  # 1 to 10 dB\n",
        "\n",
        "        # Create mixtures for each noise type\n",
        "        noise_types = ['wham', '1talker', '2talker', '4talker']\n",
        "\n",
        "        metadata = []\n",
        "\n",
        "        for noise_type in noise_types:\n",
        "            print(f\"\\\\nCreating {noise_type} mixtures...\")\n",
        "\n",
        "            for i in tqdm(range(min(num_mixtures, len(speech_files)))):\n",
        "                try:\n",
        "                    # Select random speech file\n",
        "                    speech_file = random.choice(speech_files)\n",
        "                    speech, sr = self.load_audio(speech_file)\n",
        "\n",
        "                    # Skip if too short\n",
        "                    if len(speech) < sr:  # Less than 1 second\n",
        "                        continue\n",
        "\n",
        "                    # Select random SNR\n",
        "                    snr = random.choice(snr_range)\n",
        "\n",
        "                    # Create or select noise\n",
        "                    if noise_type == 'wham' and len(noise_files) > 0:\n",
        "                        noise_file = random.choice(noise_files)\n",
        "                        noise, _ = self.load_audio(noise_file)\n",
        "                    else:\n",
        "                        num_talkers = int(noise_type[0]) if noise_type != 'wham' else 1\n",
        "                        # Exclude current speech file from babble\n",
        "                        other_files = [f for f in speech_files if f != speech_file]\n",
        "                        if len(other_files) >= num_talkers:\n",
        "                            noise = self.create_multi_talker_babble(other_files, num_talkers)\n",
        "                        else:\n",
        "                            # Fallback to synthetic noise\n",
        "                            noise = np.random.randn(len(speech)) * 0.1\n",
        "\n",
        "                    # Mix at specified SNR\n",
        "                    mixture, clean, noise_scaled = self.mix_audio_at_snr(speech, noise, snr)\n",
        "\n",
        "                    # Save files\n",
        "                    mixture_name = f'{noise_type}_{i:05d}_snr{snr}.wav'\n",
        "                    clean_name = f'{noise_type}_{i:05d}_clean.wav'\n",
        "                    noise_name = f'{noise_type}_{i:05d}_noise.wav'\n",
        "\n",
        "                    sf.write(self.output_path / 'train' / mixture_name, mixture, sr)\n",
        "                    sf.write(self.output_path / 'train' / clean_name, clean, sr)\n",
        "                    sf.write(self.output_path / 'train' / noise_name, noise_scaled, sr)\n",
        "\n",
        "                    # Store metadata\n",
        "                    metadata.append({\n",
        "                        'mixture_path': str(self.output_path / 'train' / mixture_name),\n",
        "                        'clean_path': str(self.output_path / 'train' / clean_name),\n",
        "                        'noise_path': str(self.output_path / 'train' / noise_name),\n",
        "                        'noise_type': noise_type,\n",
        "                        'snr': snr,\n",
        "                        'speech_file': str(speech_file),\n",
        "                        'duration': len(mixture) / sr\n",
        "                    })\n",
        "                except Exception as e:\n",
        "                    print(f\"Error processing file: {e}\")\n",
        "                    continue\n",
        "\n",
        "        # Save metadata\n",
        "        df = pd.DataFrame(metadata)\n",
        "        df.to_csv(self.output_path / 'train_metadata.csv', index=False)\n",
        "        print(f\"\\\\nCreated {len(metadata)} training mixtures\")\n",
        "        print(f\"Total duration: {df['duration'].sum() / 3600:.1f} hours\")\n",
        "\n",
        "        return df"
      ],
      "metadata": {
        "id": "tCDCL-QSIVnn"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    \"\"\"Main function to run data preparation\"\"\"\n",
        "    # Paths for Colab\n",
        "    librispeech_path = \"/content/data/raw/librispeech/train-clean-100\"\n",
        "    wham_path = \"\"\n",
        "    output_path = \"/content/data/processed\"\n",
        "\n",
        "    # Initialize preparer\n",
        "    preparer = CIDataPreparer(librispeech_path, wham_path, output_path)\n",
        "\n",
        "    # Prepare training data (reduced for Colab)\n",
        "    train_df = preparer.prepare_training_data(num_mixtures=100)  # Reduced from 5590\n",
        "\n",
        "    print(\"\\\\nData preparation complete!\")\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "with open('scripts/data_preparation.py', 'w') as f:\n",
        "    f.write(data_prep_code)\n",
        "\n",
        "print(\"Data preparation script saved!\")\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "bsorUFzhI1Y3",
        "outputId": "32d18ac1-e16b-499d-b742-fc2fb0c08451"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\nwith open(\\'scripts/data_preparation.py\\', \\'w\\') as f:\\n    f.write(data_prep_code)\\n\\nprint(\"Data preparation script saved!\")'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('configs/resepformer_config.yaml', 'w') as f:\n",
        "    f.write(config_yaml)\n",
        "\n",
        "print(\"Configuration file saved!\")"
      ],
      "metadata": {
        "id": "HoDgb6xyPZwj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir(\"/content/models\")\n",
        "os.getcwd()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "8pu-l4qnkoQ-",
        "outputId": "7275e364-e345-4b51-ba63-c5028c6a8f27"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/models'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from speechbrain.inference.separation import SepformerSeparation as separator\n",
        "\n",
        "model = separator.from_hparams(source= \"speechbrain/resepformer-wsj02mix\", savedir=\"pretrained_models/resepformer-wsj02mix\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443,
          "referenced_widgets": [
            "b648094105334cd5a5df4a2ebc7be67a",
            "194428c8ef8e4271896d6aab41c5d006",
            "3bdec59b7cbe47c48d9df87d42a419c2",
            "d164f3399699448a813e2583acc890a6",
            "dbbce47da68745799b158d80fb46a565",
            "f90c10e57b1f4f50afca1594e708b630",
            "73dcfd5c8b184c769ba55f537a787951",
            "6a5cfc91261c43a7b2c33ac8304c0e51",
            "97080d836c234ff48bf428af1e952bc6",
            "b2fc6d40ac4e4044a3a8b51e3b059c37",
            "971bb890c38f447199cf857d4b4f6201",
            "6df56b1eaa91497ab3924dee1037f2f3",
            "14736c8b05d640ac94e330416ee47eac",
            "f16b7af036ce4ba78cb0d981d12e9c0b",
            "35e5d595b7c2491ea355fb77fce02749",
            "fe400a5d002c443f910719164b3dceef",
            "8d761d890f4b47cbb3aac41c962c16e6",
            "92a45741044e4dd8828b4a1a61d0d431",
            "109a1b0d78bf4861aac0c19fac1af0d9",
            "f391e8c4c9df476e863868b26ba1df0f",
            "a8eb20cc643f4bb3a8e7996c39a7912a",
            "2e768a517ba042149570df7b346060c9",
            "8ac9587ded164613a1fff112996dbf70",
            "e83910c8623c4530a9a8388e18aac414",
            "a64dbadbd26c40f687439806019ae31d",
            "f179345b10a84a17ad0fb7cc7e76a8d8",
            "f56e59b34a5f4dd6951fa8afc4c49f48",
            "99dc67e1f7374ac6bb19597956411934",
            "5c5507b155e7414c91711dce0ee4bbec",
            "2144ab6317f14992a19564ca8c41a4df",
            "ac74131bfc1b48c797ce5a7417c0b374",
            "30822ea43dcf45e789847f6490e9f2c4",
            "79420baf401943bba56d318cf52789fa",
            "48b269935d8d462896b29ad71780b47a",
            "9c4f1b65ce49448887863aeec5b8783a",
            "5a61236865de452bab64e6d73ef1b9d6",
            "cd90c47ade0d4b74b5de94764537cfac",
            "683c54d13e0a43b1b7a82ac804b2e78e",
            "97cfe2a97fb14657b8fd7d8ad923dda5",
            "a92750c44cba4f8ba9ba62136c8821da",
            "af0815ae1fce461cb33727aca6108c69",
            "6c4393a6667f410484838c5c3d4eb2af",
            "a6d39b9aa04a427390a5a4e5c9e7e968",
            "d3fe9cbbca704e2eabc0aadc56b790b2"
          ]
        },
        "id": "r1VJe1oMkBQV",
        "outputId": "1cc2d16d-4b42-41fd-e43b-11a6b946b2ac"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:speechbrain.utils.fetching:Fetch hyperparams.yaml: Fetching from HuggingFace Hub 'speechbrain/resepformer-wsj02mix' if not cached\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "hyperparams.yaml: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b648094105334cd5a5df4a2ebc7be67a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:speechbrain.utils.fetching:Fetch: Local file found, creating symlink '/root/.cache/huggingface/hub/models--speechbrain--resepformer-wsj02mix/snapshots/b8e127bf2b3585c95eebbe7b786e9d3f16675156/hyperparams.yaml' -> '/content/models/pretrained_models/resepformer-wsj02mix/hyperparams.yaml'\n",
            "DEBUG:speechbrain.utils.parameter_transfer:Collecting files (or symlinks) for pretraining in pretrained_models/resepformer-wsj02mix.\n",
            "INFO:speechbrain.utils.fetching:Fetch encoder.ckpt: Fetching from HuggingFace Hub 'speechbrain/resepformer-wsj02mix' if not cached\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "encoder.ckpt:   0%|          | 0.00/9.07k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6df56b1eaa91497ab3924dee1037f2f3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:speechbrain.utils.fetching:Fetch: Local file found, creating symlink '/root/.cache/huggingface/hub/models--speechbrain--resepformer-wsj02mix/snapshots/b8e127bf2b3585c95eebbe7b786e9d3f16675156/encoder.ckpt' -> '/content/models/pretrained_models/resepformer-wsj02mix/encoder.ckpt'\n",
            "DEBUG:speechbrain.utils.parameter_transfer:Set local path in self.paths[\"encoder\"] = /content/models/pretrained_models/resepformer-wsj02mix/encoder.ckpt\n",
            "INFO:speechbrain.utils.fetching:Fetch masknet.ckpt: Fetching from HuggingFace Hub 'speechbrain/resepformer-wsj02mix' if not cached\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "masknet.ckpt:   0%|          | 0.00/186M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8ac9587ded164613a1fff112996dbf70"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:speechbrain.utils.fetching:Fetch: Local file found, creating symlink '/root/.cache/huggingface/hub/models--speechbrain--resepformer-wsj02mix/snapshots/b8e127bf2b3585c95eebbe7b786e9d3f16675156/masknet.ckpt' -> '/content/models/pretrained_models/resepformer-wsj02mix/masknet.ckpt'\n",
            "DEBUG:speechbrain.utils.parameter_transfer:Set local path in self.paths[\"masknet\"] = /content/models/pretrained_models/resepformer-wsj02mix/masknet.ckpt\n",
            "INFO:speechbrain.utils.fetching:Fetch decoder.ckpt: Fetching from HuggingFace Hub 'speechbrain/resepformer-wsj02mix' if not cached\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "decoder.ckpt:   0%|          | 0.00/9.00k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "48b269935d8d462896b29ad71780b47a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:speechbrain.utils.fetching:Fetch: Local file found, creating symlink '/root/.cache/huggingface/hub/models--speechbrain--resepformer-wsj02mix/snapshots/b8e127bf2b3585c95eebbe7b786e9d3f16675156/decoder.ckpt' -> '/content/models/pretrained_models/resepformer-wsj02mix/decoder.ckpt'\n",
            "DEBUG:speechbrain.utils.parameter_transfer:Set local path in self.paths[\"decoder\"] = /content/models/pretrained_models/resepformer-wsj02mix/decoder.ckpt\n",
            "INFO:speechbrain.utils.parameter_transfer:Loading pretrained files for: encoder, masknet, decoder\n",
            "DEBUG:speechbrain.utils.parameter_transfer:Redirecting (loading from local path): encoder -> /content/models/pretrained_models/resepformer-wsj02mix/encoder.ckpt\n",
            "DEBUG:speechbrain.utils.parameter_transfer:Redirecting (loading from local path): masknet -> /content/models/pretrained_models/resepformer-wsj02mix/masknet.ckpt\n",
            "DEBUG:speechbrain.utils.parameter_transfer:Redirecting (loading from local path): decoder -> /content/models/pretrained_models/resepformer-wsj02mix/decoder.ckpt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import speechbrain as sb\n",
        "from speechbrain.lobes.models.dual_path import Encoder, Decoder\n",
        "from speechbrain.lobes.models.resepformer import ResourceEfficientSeparator\n",
        "# Naming change in newer speechbrain versions might be nnet.normalization\n",
        "from speechbrain.nnet.normalization import LayerNorm\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class RESepFormerModel(nn.Module):\n",
        "    \"\"\"\n",
        "    RE-SepFormer implementation using SpeechBrain's ResourceEfficientSeparator\n",
        "    Configured to match Paper 2's specifications\n",
        "    \"\"\"\n",
        "    def __init__(self,\n",
        "                 n_src=2,\n",
        "                 n_filters=128,\n",
        "                 kernel_size=16,\n",
        "                 stride=8,\n",
        "                 segment_size=150,\n",
        "                 dropout=0.0,\n",
        "                 bidirectional=True,\n",
        "                 mem_type='av',\n",
        "                 norm_type='gln'):\n",
        "        super().__init__()\n",
        "\n",
        "        self.n_src = n_src\n",
        "        self.n_filters = n_filters\n",
        "\n",
        "        # Encoder - converts waveform to latent representation\n",
        "        # CORRECTED: Removed the invalid 'stride' argument.\n",
        "        # The stride is automatically set to kernel_size // 2 (which is 8 here).\n",
        "        self.encoder = Encoder(\n",
        "            kernel_size=kernel_size,\n",
        "            out_channels=n_filters,\n",
        "        )\n",
        "\n",
        "        # Normalization layer\n",
        "        # CORRECTED: Initialized with `n_filters` instead of the undefined 'normalized_shape'.\n",
        "        self.norm = LayerNorm(n_filters)\n",
        "\n",
        "        # RE-SepFormer separator - the key component from Paper 2\n",
        "        self.separator = ResourceEfficientSeparator(\n",
        "            input_dim=n_filters,\n",
        "            causal=False,\n",
        "            num_spk=n_src,\n",
        "            nonlinear='relu',\n",
        "            layer=8,\n",
        "            unit=512,\n",
        "            segment_size=segment_size,\n",
        "            dropout=dropout,\n",
        "            # Removed mem_type as it might be causing the \"Unsupported segment model class\" error\n",
        "            # mem_type=mem_type\n",
        "        )\n",
        "\n",
        "        # Decoder - converts back to waveform\n",
        "        self.decoder = Decoder(\n",
        "            in_channels=n_filters,\n",
        "            out_channels=1,\n",
        "            kernel_size=kernel_size,\n",
        "            stride=stride,\n",
        "            bias=False\n",
        "        )\n",
        "\n",
        "    def forward(self, mixture):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            mixture: [batch, time]\n",
        "        Returns:\n",
        "            separated: [batch, n_src, time]\n",
        "        \"\"\"\n",
        "        # Encode the mixture: [B, time] -> [B, N, L]\n",
        "        mixture_encoded = self.encoder(mixture)\n",
        "\n",
        "        # CORRECTED: Transpose for LayerNorm, apply norm, and transpose back.\n",
        "        # LayerNorm expects features in the last dimension.\n",
        "        # [B, N, L] -> [B, L, N]\n",
        "        mixture_transposed = mixture_encoded.transpose(1, 2)\n",
        "        # [B, L, N] -> [B, L, N]\n",
        "        mixture_normalized_transposed = self.norm(mixture_transposed)\n",
        "        # [B, L, N] -> [B, N, L]\n",
        "        mixture_normalized = mixture_normalized_transposed.transpose(1, 2)\n",
        "\n",
        "        # Separate sources. The separator expects input of shape [B, N, L]\n",
        "        # and returns masks of shape [B, n_src, N, L]\n",
        "        masks = self.separator(mixture_normalized)\n",
        "\n",
        "        # Apply masks to get separated encodings\n",
        "        # mixture_encoded [B, N, L] -> unsqueeze to [1, B, N, L] for broadcasting\n",
        "        # masks          [B, n_src, N, L] -> permute to [n_src, B, N, L]\n",
        "        masked = mixture_encoded.unsqueeze(1) * masks.permute(1, 0, 2, 3)\n",
        "        masked = masked.permute(1, 0, 2, 3) # [n_src, B, N, L]\n",
        "\n",
        "        # Decode each source\n",
        "        separated_sources = []\n",
        "        for i in range(self.n_src):\n",
        "            # [B, N, L] -> [B, 1, time]\n",
        "            decoded = self.decoder(masked[i])\n",
        "            separated_sources.append(decoded.squeeze(1))\n",
        "\n",
        "        # Stack sources: list of [B, time] -> [B, n_src, time]\n",
        "        separated = torch.stack(separated_sources, dim=1)\n",
        "\n",
        "        return separated"
      ],
      "metadata": {
        "id": "dbMEsSWm5Qci"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = RESepFormerModel(n_src=1)  # Single source for enhancement\n",
        "print(f\"Model created with {sum(p.numel() for p in model.parameters()):,} parameters\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jdMkVyIMYGGF",
        "outputId": "284ece08-b230-45cf-f194-6d112ab65492"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model created with 20,865 parameters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "\n",
        "Data Preparation Following Paper 1\n",
        "\n",
        "\n",
        "Create CI-specific Dataset\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "_Xer_fmK5zCN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import random\n",
        "from pathlib import Path"
      ],
      "metadata": {
        "id": "S-q-meFy8oKS"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CochlearImplantDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Dataset following Paper 1's methodology:\n",
        "    - LibriSpeech + WHAM! noise\n",
        "    - Multi-talker babble creation\n",
        "    - SNRs from 1-10 dB\n",
        "    \"\"\"\n",
        "    def __init__(self,\n",
        "                 speech_dir,\n",
        "                 noise_dir,\n",
        "                 sample_rate=16000,\n",
        "                 segment_duration=4.0,\n",
        "                 snr_range=(1, 10),\n",
        "                 noise_types=['wham', '1talker', '2talker', '4talker']):\n",
        "\n",
        "        self.speech_dir = Path(speech_dir)\n",
        "        self.noise_dir = Path(noise_dir)\n",
        "        self.sample_rate = sample_rate\n",
        "        self.segment_len = int(segment_duration * sample_rate)\n",
        "        self.snr_range = snr_range\n",
        "        self.noise_types = noise_types\n",
        "\n",
        "        # Collect audio files\n",
        "        self.speech_files = list(self.speech_dir.glob('**/*.flac'))\n",
        "        self.noise_files = list(self.noise_dir.glob('**/*.wav'))\n",
        "\n",
        "        print(f\"Found {len(self.speech_files)} speech files\")\n",
        "        print(f\"Found {len(self.noise_files)} noise files\")\n",
        "\n",
        "        # Create mixture combinations\n",
        "        self._create_mixtures()\n",
        "\n",
        "    def _create_mixtures(self):\n",
        "        \"\"\"Create mixture combinations as per Paper 1\"\"\"\n",
        "        self.mixtures = []\n",
        "\n",
        "        # Following Paper 1: 5590 mixtures per noise type\n",
        "        mixtures_per_type = min(100, len(self.speech_files))  # Reduced for demo\n",
        "\n",
        "        for noise_type in self.noise_types:\n",
        "            for _ in range(mixtures_per_type):\n",
        "                speech_file = random.choice(self.speech_files)\n",
        "                snr = random.randint(*self.snr_range)\n",
        "\n",
        "                if noise_type == 'wham' and self.noise_files:\n",
        "                    noise_file = random.choice(self.noise_files)\n",
        "                else:\n",
        "                    # For multi-talker babble\n",
        "                    noise_file = None\n",
        "\n",
        "                self.mixtures.append({\n",
        "                    'speech_file': speech_file,\n",
        "                    'noise_file': noise_file,\n",
        "                    'noise_type': noise_type,\n",
        "                    'snr': snr\n",
        "                })\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.mixtures)\n",
        "\n",
        "    def _load_audio(self, path):\n",
        "        \"\"\"Load and resample audio if needed\"\"\"\n",
        "        import librosa\n",
        "        audio, sr = librosa.load(path, sr=self.sample_rate, mono=True)\n",
        "        return audio\n",
        "\n",
        "    def _create_babble(self, num_talkers):\n",
        "        \"\"\"Create multi-talker babble\"\"\"\n",
        "        babble_files = random.sample(self.speech_files, min(num_talkers, len(self.speech_files)))\n",
        "\n",
        "        babble = None\n",
        "        for file in babble_files:\n",
        "            audio = self._load_audio(file)\n",
        "            if babble is None:\n",
        "                babble = audio\n",
        "            else:\n",
        "                # Mix at equal levels\n",
        "                min_len = min(len(babble), len(audio))\n",
        "                babble[:min_len] += audio[:min_len]\n",
        "\n",
        "        # Normalize\n",
        "        babble = babble / (np.max(np.abs(babble)) + 1e-8)\n",
        "        return babble\n",
        "\n",
        "    def _mix_at_snr(self, speech, noise, snr_db):\n",
        "        \"\"\"Mix speech and noise at specified SNR\"\"\"\n",
        "        # Match lengths\n",
        "        if len(noise) < len(speech):\n",
        "            noise = np.tile(noise, (len(speech) // len(noise) + 1))\n",
        "        noise = noise[:len(speech)]\n",
        "\n",
        "        # Calculate gains\n",
        "        speech_power = np.mean(speech ** 2)\n",
        "        noise_power = np.mean(noise ** 2)\n",
        "\n",
        "        noise_gain = np.sqrt(speech_power / (noise_power * (10 ** (snr_db / 10))))\n",
        "\n",
        "        # Mix\n",
        "        mixture = speech + noise * noise_gain\n",
        "\n",
        "        # Prevent clipping\n",
        "        max_val = np.max(np.abs(mixture))\n",
        "        if max_val > 0.95:\n",
        "            scale = 0.95 / max_val\n",
        "            mixture *= scale\n",
        "            speech *= scale\n",
        "\n",
        "        return mixture, speech\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"Get a mixture sample\"\"\"\n",
        "        item = self.mixtures[idx]\n",
        "\n",
        "        # Load speech\n",
        "        speech = self._load_audio(item['speech_file'])\n",
        "\n",
        "        # Create or load noise\n",
        "        if item['noise_type'] == 'wham' and item['noise_file']:\n",
        "            noise = self._load_audio(item['noise_file'])\n",
        "        else:\n",
        "            # Create multi-talker babble\n",
        "            num_talkers = int(item['noise_type'][0]) if item['noise_type'] != 'wham' else 1\n",
        "            noise = self._create_babble(num_talkers)\n",
        "\n",
        "        # Mix at specified SNR\n",
        "        mixture, clean_speech = self._mix_at_snr(speech, noise, item['snr'])\n",
        "\n",
        "        # Truncate or pad to fixed length\n",
        "        if len(mixture) > self.segment_len:\n",
        "            start = random.randint(0, len(mixture) - self.segment_len)\n",
        "            mixture = mixture[start:start + self.segment_len]\n",
        "            clean_speech = clean_speech[start:start + self.segment_len]\n",
        "        else:\n",
        "            pad_len = self.segment_len - len(mixture)\n",
        "            mixture = np.pad(mixture, (0, pad_len))\n",
        "            clean_speech = np.pad(clean_speech, (0, pad_len))\n",
        "\n",
        "        return {\n",
        "            'mixture': torch.FloatTensor(mixture),\n",
        "            'clean': torch.FloatTensor(clean_speech),\n",
        "            'snr': item['snr'],\n",
        "            'noise_type': item['noise_type']\n",
        "        }"
      ],
      "metadata": {
        "id": "cEshsuBn55pr"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir(\"/content\")\n",
        "os.getcwd()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "g6UgKCNT_vok",
        "outputId": "b3eeed9d-cf3e-4d8e-f542-ee438344cec7"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create dataset\n",
        "dataset = CochlearImplantDataset(\n",
        "    speech_dir='data/raw/librispeech/LibriSpeech/train-clean-100',\n",
        "    noise_dir='data/raw/wham/wham_noise/tr',\n",
        "    segment_duration=4.0  # 4 seconds for manageable training\n",
        ")\n",
        "\n",
        "print(f\"Created dataset with {len(dataset)} mixtures\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQQn1u7P_U5q",
        "outputId": "cbfc70d0-d2a8-4b35-f30a-4ec789f62f78"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 28539 speech files\n",
            "Found 20000 noise files\n",
            "Created dataset with 400 mixtures\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "Training Pipeline\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "2FbR5mobAXvk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "###Loss Functions and Training Setup\n",
        "\n",
        "\n",
        "def si_snr_loss(estimate, target, eps=1e-8):\n",
        "    \"\"\"\n",
        "    Scale-Invariant Signal-to-Noise Ratio loss\n",
        "    Used in both Paper 1 and Paper 2\n",
        "    \"\"\"\n",
        "    # Ensure same length\n",
        "    min_len = min(estimate.shape[-1], target.shape[-1])\n",
        "    estimate = estimate[..., :min_len]\n",
        "    target = target[..., :min_len]\n",
        "\n",
        "    # Remove mean\n",
        "    estimate = estimate - torch.mean(estimate, dim=-1, keepdim=True)\n",
        "    target = target - torch.mean(target, dim=-1, keepdim=True)\n",
        "\n",
        "    # Compute SI-SNR\n",
        "    dot = torch.sum(estimate * target, dim=-1, keepdim=True)\n",
        "    target_energy = torch.sum(target ** 2, dim=-1, keepdim=True) + eps\n",
        "\n",
        "    projection = dot * target / target_energy\n",
        "    noise = estimate - projection\n",
        "\n",
        "    si_snr = 10 * torch.log10(\n",
        "        torch.sum(projection ** 2, dim=-1) / (torch.sum(noise ** 2, dim=-1) + eps)\n",
        "    )\n",
        "\n",
        "    return -torch.mean(si_snr)  # Negative for minimization\n"
      ],
      "metadata": {
        "id": "NVI52bNt_5gE"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Trainer:\n",
        "    \"\"\"Training pipeline for RE-SepFormer\"\"\"\n",
        "    def __init__(self, model, device='cuda'):\n",
        "        self.model = model.to(device)\n",
        "        self.device = device\n",
        "        self.optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "        self.scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "            self.optimizer, patience=3, factor=0.5\n",
        "        )\n",
        "\n",
        "    def train_epoch(self, dataloader):\n",
        "        \"\"\"Train for one epoch\"\"\"\n",
        "        self.model.train()\n",
        "        total_loss = 0\n",
        "\n",
        "        for batch in tqdm(dataloader, desc=\"Training\"):\n",
        "            mixture = batch['mixture'].to(self.device)\n",
        "            clean = batch['clean'].to(self.device)\n",
        "\n",
        "            # Forward pass\n",
        "            separated = self.model(mixture)\n",
        "\n",
        "            # For single source enhancement, use first output\n",
        "            if separated.shape[1] > 1:\n",
        "                estimate = separated[:, 0, :]\n",
        "            else:\n",
        "                estimate = separated.squeeze(1)\n",
        "\n",
        "            # Compute loss\n",
        "            loss = si_snr_loss(estimate, clean)\n",
        "\n",
        "            # Backward pass\n",
        "            self.optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(self.model.parameters(), 5.0)\n",
        "            self.optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        avg_loss = total_loss / len(dataloader)\n",
        "        return avg_loss\n",
        "\n",
        "    def evaluate(self, dataloader):\n",
        "        \"\"\"Evaluate model\"\"\"\n",
        "        self.model.eval()\n",
        "        total_loss = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch in tqdm(dataloader, desc=\"Evaluating\"):\n",
        "                mixture = batch['mixture'].to(self.device)\n",
        "                clean = batch['clean'].to(self.device)\n",
        "\n",
        "                # Forward pass\n",
        "                separated = self.model(mixture)\n",
        "\n",
        "                if separated.shape[1] > 1:\n",
        "                    estimate = separated[:, 0, :]\n",
        "                else:\n",
        "                    estimate = separated.squeeze(1)\n",
        "\n",
        "                # Compute loss\n",
        "                loss = si_snr_loss(estimate, clean)\n",
        "                total_loss += loss.item()\n",
        "\n",
        "        avg_loss = total_loss / len(dataloader)\n",
        "        return avg_loss"
      ],
      "metadata": {
        "id": "4MKvOsiWApR9"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the Model"
      ],
      "metadata": {
        "id": "R4TQay1hA8pV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create data loaders\n",
        "train_loader = DataLoader(\n",
        "    dataset,\n",
        "    batch_size=4,  # Small batch size for Colab\n",
        "    shuffle=True,\n",
        "    num_workers=2\n",
        ")"
      ],
      "metadata": {
        "id": "xY0Zt5G1AuSS"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = RESepFormerModel(n_src=1)  # Single source for CI enhancement\n",
        "trainer = Trainer(model, device)"
      ],
      "metadata": {
        "id": "PrybaStkBFj-"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop (reduced for demo)\n",
        "num_epochs = 70  # Paper 1 used 100 epochs\n",
        "best_loss = float('inf')\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"\\n--- Epoch {epoch+1}/{num_epochs} ---\")\n",
        "\n",
        "    # Train\n",
        "    train_loss = trainer.train_epoch(train_loader)\n",
        "    print(f\"Training loss: {train_loss:.4f}\")\n",
        "\n",
        "    # Save checkpoint\n",
        "    if train_loss < best_loss:\n",
        "        best_loss = train_loss\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': trainer.optimizer.state_dict(),\n",
        "            'loss': train_loss\n",
        "        }, 'best_model.pth')\n",
        "        print(\"Saved best model!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "GH0zSvr4BKgL",
        "outputId": "d81ac5ab-7af2-440b-ff4c-e6183c3e0106"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Epoch 1/70 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   0%|          | 0/100 [00:02<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Unsupported segment model class",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-115-3397514894.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# Train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Training loss: {train_loss:.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-111-2750382856.py\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(self, dataloader)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0;31m# Forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0mseparated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmixture\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0;31m# For single source enhancement, use first output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-106-402691660.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, mixture)\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;31m# Separate sources. The separator expects input of shape [B, N, L]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;31m# and returns masks of shape [B, n_src, N, L]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0mmasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseparator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmixture_normalized\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;31m# Apply masks to get separated encodings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/speechbrain/speechbrain/lobes/models/resepformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inpt)\u001b[0m\n\u001b[1;32m    766\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m         \u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 768\u001b[0;31m         \u001b[0mprocessed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minpt\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# B,T, N\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    769\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m         \u001b[0mprocessed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocessed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_spk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/speechbrain/speechbrain/lobes/models/resepformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    620\u001b[0m                 \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseg_model\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhc\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# BS, K, D\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    621\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 622\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unsupported segment model class\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    623\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_blocks\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Unsupported segment model class"
          ]
        }
      ]
    }
  ]
}